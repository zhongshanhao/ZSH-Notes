线程安全的集合类可以分为三大类

1. 遗留的线程安全集合类如`Hashtable`，`Vector`

拿Hashtable为例，它的实现仅仅是在对共享变量有读写的方法上加了`synchronized`，保证共享变量的线程安全，比如`size()`、`isEmpty()`、`get()`、`put()`、`remove()`方法等。

2. 使用Collections装饰的线程安全集合，如`Collections.synchronizedList`，`Collections.synchronizedMap`等等

```java
	// 定义了一个非线程安全的map集合
	Map<String, Integer> map = new HashMap<>();
	// 通过Collections的包装方法，用map新生成了一个线程安全的map
    Map<String, Integer> safeMap = Collections.synchronizedMap(map);
	
    public static <K,V> Map<K,V> synchronizedMap(Map<K,V> m) {
        return new SynchronizedMap<>(m);
    }
```

查看SynchronizedMap集合源码，可以看到JDK是利用装饰器模式的思想包装了一下map，还是调用的是HashMap中的方法，只是在调用原来方法的时候加了`synchronized`关键字保证线程安全，实际上和`Hashtable`相似。

> 装饰器模式：指在不改变现有对象结构的情况下，动态地给该对象增加一些职责（即增加其额外功能）的模式，它是作为现有的类的一个包装。

![SynchronizedMap](https://gitee.com/Krains/FigureBed/raw/master/img/SynchronizedMap.png)

3. `java.util.concurrent.*`包下的线程安全集合类，根据它们各自的特点分为3类：Blocking、CopyOnWrite、Concurrent

Blocking大部分实现是基于锁的，并提供用来阻塞的方法

CopyOnWrite适合用在多线程读多写少的情况

Concurrent类型的容器，在内部很多操作使用cas优化，可以提高较高的吞吐量，但是存在弱一致性问题

- 遍历时弱一致性，当利用迭代器遍历时，如果容器发生修改，迭代器仍然可以继续遍历，但是内容是旧的
- 求大小时弱一致性，size操作未必是100%准确
- 读取弱一致性

## JDK1.7 ConcurrentHashMap

本质上ConcurrentHashMap就是一个Segment数组，而一个Segment实例则是一个小的哈希表。由于Segment类继承于ReentrantLock类，从而使得Segment对象能充当锁的角色，这样，每个 Segment对象就可以守护整个ConcurrentHashMap的若干个桶，其中每个桶是由若干个HashEntry对象链接起来的链表。

通过使用段(Segment)将ConcurrentHashMap划分为不同的部分，ConcurrentHashMap就可以使用不同的锁来控制对哈希表的不同部分的修改，从而允许多个修改操作并发进行, 这正是ConcurrentHashMap锁分段技术的核心内涵。

结构图

![ConcurrentHashMap1.7结构图](https://gitee.com/Krains/FigureBed/raw/master/img/ConcurrentHashMap1.7%E7%BB%93%E6%9E%84%E5%9B%BE.jpg)

### 重要属性

```java
    // 默认Segment数组中桶的数量
	static final int DEFAULT_INITIAL_CAPACITY = 16;

    static final float DEFAULT_LOAD_FACTOR = 0.75f;

	// 默认的并发级别，其实就是Segment数组的大小，每个segment可以并发修改
    static final int DEFAULT_CONCURRENCY_LEVEL = 16;

	// 每个segment中最少的桶数量是二
	static final int MIN_SEGMENT_TABLE_CAPACITY = 2;

	// 没有加volatile
    final Segment<K,V>[] segments;
```

Segment继承了ReentrantLock，它的重要属性如下

```java
    static final class Segment<K,V> extends ReentrantLock implements Serializable {

		static final int MAX_SCAN_RETRIES =
            Runtime.getRuntime().availableProcessors() > 1 ? 64 : 1;
		
		// 每个segment下有几个hash桶，加了volatile保证内存可见性
        transient volatile HashEntry<K,V>[] table;

		// 以下都是hash桶的重要属性
        transient int count;

        transient int threshold;

        final float loadFactor;
    	
        // ...
    }
```

HashEntry，与HashMap相比多了两个volatile关键词修饰，保证变量的内存可见性

```java
    static final class HashEntry<K,V> {
        final int hash;
        final K key;
        // 使用volatile修饰，保证变量可见性
        volatile V value;
        volatile HashEntry<K,V> next;
    	
        // ...
    }
```

### 构造函数

```java
    public ConcurrentHashMap(int initialCapacity,
                             float loadFactor, int concurrencyLevel) {
        if (!(loadFactor > 0) || initialCapacity < 0 || concurrencyLevel <= 0)
            throw new IllegalArgumentException();
        if (concurrencyLevel > MAX_SEGMENTS)
            concurrencyLevel = MAX_SEGMENTS;
        // Find power-of-two sizes best matching arguments
        int sshift = 0;
        // segments数组的大小，必须是2的幂次方，它的值是大于concurrencyLevel的最小值
        int ssize = 1;
        while (ssize < concurrencyLevel) {
            ++sshift;
            ssize <<= 1;
        }
        // 用于定位段，hash值的最后sshift位
        this.segmentShift = 32 - sshift;
        this.segmentMask = ssize - 1;
        if (initialCapacity > MAXIMUM_CAPACITY)
            initialCapacity = MAXIMUM_CAPACITY;
        int c = initialCapacity / ssize;
        if (c * ssize < initialCapacity)
            ++c;
        // c是每个segment必须包含桶的最小个数
        int cap = MIN_SEGMENT_TABLE_CAPACITY;
        // 桶的数量也必须是2的幂次，所以和 segments数组的大小 做同样的处理
        while (cap < c)
            cap <<= 1;
        // create segments and segments[0]
        // 创建一个桶做模板用，就不用每次计算桶大小了
        Segment<K,V> s0 =
            new Segment<K,V>(loadFactor, (int)(cap * loadFactor),
                             (HashEntry<K,V>[])new HashEntry[cap]);
        Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];
        UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]
        this.segments = ss;
    }
```

### put()

ConcurrentHashMap的put操作，通过key定位到某个segment，之后在对应的segment中进行具体的put

```java
    public V put(K key, V value) {
        Segment<K,V> s;
        // 不支持插入null值
        if (value == null)
            throw new NullPointerException();
        int hash = hash(key);
        int j = (hash >>> segmentShift) & segmentMask;
        // 获得 segment 对象, 判断是否为 null, 是则创建该 segment
        if ((s = (Segment<K,V>)UNSAFE.getObject          // nonvolatile; recheck
             (segments, (j << SSHIFT) + SBASE)) == null) //  in ensureSegment
        // 这时不能确定是否真的为 null, 因为其它线程也发现该 segment 为 null,
		// 因此在 ensureSegment 里用 cas 方式保证该 segment 安全性
            s = ensureSegment(j);
        // 进入 segment 的put 流程
        return s.put(key, hash, value, false);
    }

	// 返回给定索引的segment，如果对应segment为空则用CAS去创建它
    private Segment<K,V> ensureSegment(int k) {
        final Segment<K,V>[] ss = this.segments;
        long u = (k << SSHIFT) + SBASE; // raw offset
        Segment<K,V> seg;
        // 判断对应segment是否为空
        if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) {
            Segment<K,V> proto = ss[0]; // use segment 0 as prototype
            int cap = proto.table.length;
            float lf = proto.loadFactor;
            int threshold = (int)(cap * lf);
            HashEntry<K,V>[] tab = (HashEntry<K,V>[])new HashEntry[cap];
            
            if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u))
                == null) { // recheck
                Segment<K,V> s = new Segment<K,V>(lf, threshold, tab);
                while ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u))
                       == null) {
                    if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s))
                        break;
                }
            }
        }
        return seg;
    }
```

Segment继承了可重入锁，Segment中的put操作如下

```java
final V put(K key, int hash, V value, boolean onlyIfAbsent) {
            // 尝试加锁
            // 如果不成功, 进入 scanAndLockForPut 流程
            // 如果是多核 cpu 最多 tryLock 64 次, 进入 lock 流程
            // 在尝试期间, 还可以顺便看该节点在链表中有没有, 如果没有顺便创建出来
    		HashEntry<K,V> node = tryLock() ? null :
                scanAndLockForPut(key, hash, value);
    		// 运行到此处 segment 已经被成功加锁，可以安全执行
            V oldValue;
            try {
                HashEntry<K,V>[] tab = table;
                int index = (tab.length - 1) & hash;
                HashEntry<K,V> first = entryAt(tab, index);
                for (HashEntry<K,V> e = first;;) {
                    if (e != null) {
                        K k;
                        if ((k = e.key) == key ||
                            (e.hash == hash && key.equals(k))) {
                            oldValue = e.value;
                            if (!onlyIfAbsent) {
                                e.value = value;
                                ++modCount;
                            }
                            break;
                        }
                        e = e.next;
                    }
                    else {
                        if (node != null)
                            node.setNext(first);
                        else
                            node = new HashEntry<K,V>(hash, key, value, first);
                        int c = count + 1;
                        // 扩容时因为已经获得锁了，所以扩容操作是线程安全的
                        if (c > threshold && tab.length < MAXIMUM_CAPACITY)
                            rehash(node);
                        else
                            setEntryAt(tab, index, node);
                        ++modCount;
                        count = c;
                        oldValue = null;
                        break;
                    }
                }
            } finally {
                unlock();
            }
            return oldValue;
        }
```

每个segment本身就是一把锁，线程需要put操作时需要获得锁，每个锁下面管理了很多个桶，每个segment之间是相互独立的（不管是扩容还是添加）
- 尝试自旋获取锁
- 如果重试次数大于 MAX_SCAN_RETRIES 则改为阻塞获取，保证能够获取到锁

### get()操作

```java
    public V get(Object key) {
        Segment<K,V> s; // manually integrate access methods to reduce overhead
        HashEntry<K,V>[] tab;
        int h = hash(key);
        long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;
        if ((s = (Segment<K,V>)UNSAFE.getObjectVolatile(segments, u)) != null &&
            (tab = s.table) != null) {
            for (HashEntry<K,V> e = (HashEntry<K,V>) UNSAFE.getObjectVolatile
                     (tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE);
                 e != null; e = e.next) {
                K k;
                if ((k = e.key) == key || (e.hash == h && key.equals(k)))
                    return e.value;
            }
        }
        return null;
    }
```

由于HashEntry中的value属性是由volatile关键词修饰的，保证了内存的可见性。

- 首先通过key得到hash值，然后通过hash值定位到具体的segment
- 然后在segment中在通过hash值定位到具体的桶中，然后遍历链表

### size()操作

```java
    public int size() {
        // Try a few times to get accurate count. On failure due to
        // continuous async changes in table, resort to locking.
        final Segment<K,V>[] segments = this.segments;
        int size;
        boolean overflow; // true if size overflows 32 bits
        long sum;         // sum of modCounts
        long last = 0L;   // previous sum
        int retries = -1; // first iteration isn't retry
        try {
            for (;;) {
                if (retries++ == RETRIES_BEFORE_LOCK) {
                    for (int j = 0; j < segments.length; ++j)
                        ensureSegment(j).lock(); // force creation
                }
                sum = 0L;
                size = 0;
                overflow = false;
                for (int j = 0; j < segments.length; ++j) {
                    Segment<K,V> seg = segmentAt(segments, j);
                    if (seg != null) {
                        sum += seg.modCount;
                        int c = seg.count;
                        if (c < 0 || (size += c) < 0)
                            overflow = true;
                    }
                }
                if (sum == last)
                    break;
                last = sum;
            }
        } finally {
            if (retries > RETRIES_BEFORE_LOCK) {
                for (int j = 0; j < segments.length; ++j)
                    segmentAt(segments, j).unlock();
            }
        }
        return overflow ? Integer.MAX_VALUE : size;
    }
```

- 第一种方案他会使用不加锁的模式去尝试多次计算ConcurrentHashMap的size，最多三次，比较前后两次计算的结果，结果一致就认为当前没有元素加入，计算的结果是准确的
- 第二种方案是如果第一种方案不符合，他就会给每个Segment加上锁，然后计算ConcurrentHashMap的size返回(美团面试官的问题,多个线程下如何确定size)

## JDK1.8ConcurrentHashMap

### 重要属性

```java
	transient volatile Node<K,V>[] table;

	static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        volatile V val;
        volatile Node<K,V> next;
    	// ...
    }
```

### 重要的cas方法

```java
// cas 修改 Node[] 中第 i 个 Node 的值, c 为旧值, v 为新值
// 如果内存中的值与c相等，则用新值替换旧值
static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i, Node<K,V> c, Node<K,V> v)
```

### 构造方法

```java
    // 默认构造方法，啥都不做，懒惰初始化，并没有初始化table
	public ConcurrentHashMap() {
    }

	public ConcurrentHashMap(int initialCapacity,
                             float loadFactor, int concurrencyLevel) {
        if (!(loadFactor > 0.0f) || initialCapacity < 0 || concurrencyLevel <= 0)
            throw new IllegalArgumentException();
        if (initialCapacity < concurrencyLevel)   // Use at least as many bins
            initialCapacity = concurrencyLevel;   // as estimated threads
        long size = (long)(1.0 + (long)initialCapacity / loadFactor);
        // 保证cap桶大小为2的幂次
        int cap = (size >= (long)MAXIMUM_CAPACITY) ?
            MAXIMUM_CAPACITY : tableSizeFor((int)size);
        this.sizeCtl = cap;
    }
```

### 初始化table

```java
    private final Node<K,V>[] initTable() {
        Node<K,V>[] tab; int sc;
        while ((tab = table) == null || tab.length == 0) {
            if ((sc = sizeCtl) < 0)
                Thread.yield(); // lost initialization race; just spin
            // 使用cas操作完成table的初始化，保证线程安全
            else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
                try {
                    if ((tab = table) == null || tab.length == 0) {
                        int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                        @SuppressWarnings("unchecked")
                        Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                        table = tab = nt;
                        sc = n - (n >>> 2);
                    }
                } finally {
                    sizeCtl = sc;
                }
                break;
            }
        }
        return tab;
    }
```

双重校验+CAS保证数组只会初始化一次

- 第一次校验：进入while循环时，校验是否table为空或者数组长度为0
- 使用CAS保证数组初始化的原子性
- 第二次校验：在CAS内部再次校验是否table为空或者数组长度为0

sizeCtl：默认为0，sizeCtl中记录size大小的偏移量，用来控制table的初始化和扩容操作，它的数值有一下含义

- -1：代表table正在初始化，其他线程应该交出CPU时间片
- -N：表示当前有N-1个线程执行扩容操作
- \>0：表示table初始化或扩容完成后，为下一次的扩容的阈值大小

### get()方法

```java
    public V get(Object key) {
        Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
        int h = spread(key.hashCode());
        // 如果当前数组不为空，且对应桶不为空
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (e = tabAt(tab, (n - 1) & h)) != null) {
            // 还是先比较第一个结点
            if ((eh = e.hash) == h) {
                if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                    return e.val;
            }
            // hash为负数表示该 bin 在扩容或是 treebin，这是调用find方法查找
            else if (eh < 0)
                return (p = e.find(h, key)) != null ? p.val : null;
            // 正常遍历链表, 用 equals 比较
            while ((e = e.next) != null) {
                if (e.hash == h &&
                    ((ek = e.key) == key || (ek != null && key.equals(ek))))
                    return e.val;
            }
        }
        return null;
    }
```

在value上加上volatile关键字保证内存可见性

### put()方法

以下数组简称(table)，链表简称(bin)

```java
    final V putVal(K key, V value, boolean onlyIfAbsent) {
        if (key == null || value == null) throw new NullPointerException();
        int hash = spread(key.hashCode());
        int binCount = 0;
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh;
            // 如果对应table还未初始化，使用cas操作完成table的初始化，保证线程安全
            if (tab == null || (n = tab.length) == 0)
                tab = initTable();
            // 如果对应桶为空，则使用cas添加结点，然后直接break
            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
				// 添加链表头使用了 cas, 无需 synchronized
                if (casTabAt(tab, i, null,
                             new Node<K,V>(hash, key, value, null)))
                    break;                   // no lock when adding to empty bin
            }
            // 如果当前桶的第一个结点是转移结点，表示该位置正在扩容，帮助扩容
            else if ((fh = f.hash) == MOVED)
                tab = helpTransfer(tab, f);
            else {
                V oldVal = null;
                // 直接锁住链表头，其他线程不能操作
                synchronized (f) {
                    // 再次确认链表头节点没有被移动
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) {
                            binCount = 1;
                            for (Node<K,V> e = f;; ++binCount) {
                                K ek;
                                if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                     (ek != null && key.equals(ek)))) {
                                    oldVal = e.val;
                                    if (!onlyIfAbsent)
                                        e.val = value;
                                    break;
                                }
                                Node<K,V> pred = e;
                                if ((e = e.next) == null) {
                                    pred.next = new Node<K,V>(hash, key,
                                                              value, null);
                                    break;
                                }
                            }
                        }
                        else if (f instanceof TreeBin) {
                            Node<K,V> p;
                            binCount = 2;
                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                           value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                    }
                }
                if (binCount != 0) {
                    if (binCount >= TREEIFY_THRESHOLD)
                        treeifyBin(tab, i);
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        addCount(1L, binCount);
        return null;
    }
```

### 扩容

- 先把原数组中的值拷贝到扩容后的新数组上，从数组的尾巴开始拷贝
- 拷贝某个桶时，先把这个桶用synchronized锁住，保证不能够被put，成功拷贝到新数组时，应该把原数组的桶设置为转移结点
- 如果此时有新数据正好需要put到这个桶时，发现桶为转移结点，就会帮助扩容，扩容完成后在put到新数组中。
- 所有数组数据都拷贝到新数组中时，直接把新数组整个赋值给原数组引用。

总结1.8中是如何保证线程安全的

- 初始化table时，采用双重校验+cas来保证并发安全
- put操作，如果对应桶位置为null，使用cas创建结点，如果有，则锁住链表头进行后续put操作，元素添加到链表尾部

