star法则

- situation(在什么样的情况发生的，具体需求是什么)
- task(具体的任务)
- action(针对这样的情况和任务，我是怎么采取行动的)
- result(结果如何，所做的事产生的影响，收获是什么)

#### 新工单系统

situation

- 老工单bug不断，运维费时
- 老工单的架构前后端不分离，没有使用任何流程引擎和开源组件，代码不易扩展和维护

task

- 技术选型
  - 自研，之前的就是自研的，如果再自研一套代码量大，工作量大
  - Activity，支持BPMN标准的流程定义语言，提供完善的流程控制支持
  - Flowable，是之前Activity团队离开之前公司在Activity6.0分支的基础上开发的，有更加完善的功能，如支持表单，支持REST API进行HTTP调用，国内盘古BPM做的比较完善的流程引擎系统也是基于Flowable
- 整理老工单的功能，需要全部在新工单上实现

action

- 前后端分离，使用流程引擎Flowable开发，使用一些设计模式开发，代码简洁易维护，
- 开发一套简单工单适配老工单系统，功能包括审批通过、拒绝驳回修改、评论，回调接口，开发复杂工单作为扩展支持复杂的流程定义
- 新工单的适配工作，不能一股脑直接全部迁移到新工单，需要做适配工作
  - 如爱奇艺云展示工单列表页面分别展示新工单和老工单，涉及到两个不同数据源分页的问题
  - 新工单同步OA审批中心，在老工单中，工单都是要同步给OA的，然后OA那边也可以进行工单审批，驳回，评论一些列操作嘛。新工单同步OA是这样做的，我们可以将根据OA提供的接口把工单信息同步、审批操作同步过去，然后那边操作新工单的话还是调的老工单的接口嘛，我们在老工单系统里做了消息的转发，转发到新工单完成信息的同步的。

result

- 完成新工单系统，能够适配老工单系统的功能，且扩展了复杂工单流程

- 收获了项目经验，学会使用设计模式增加项目的可维护性和扩展性

我的思考

通用的解决方法，更宽的业务场景

flowable流程引擎拓展，阅读源代码，增加监听器

#### 螺丝配卡

**situation**

我们在使用图像围栏的时候，需要给不同的服务配GPU卡，比如我给人脸特征抽取配8张卡，我们可以有1个实例配8卡，4实例每个配两卡策略，这4个实例分配到不同的机器上，不同分配策略不一样，它们有不同的QPS、内存和CPU消耗，这其实跟服务有关系，有些服务偏向于IO密集型，有些偏向计算密集型，计算密集型的服务均分到不同的机器上能够充分利用CPU资源，而IO密集型的服务应该尽量起1个实例，分在一台机器上会好些。

**task**

所以，我的任务就是我们在给各个服务配好GPU卡之后，考量整体的服务给出一个每一个服务的实例数与它的GPU卡数，因为我们集群的机器和GPU卡数是有限的，需要尽可能充分利用有限的资源获得更好的性能。

**action**

- 当然，首先第一步就是判断每一个服务是计算密集型还是IO密集型的，这需要通过业务逻辑和性能测试两个方面来做判断
- 我们将所有的服务归好类，我们要综合所有服务使用特定的算法得到每一个服务的分配策略

**result**

测试

对照实验

- 所有服务统统分配1*n，1卡多实例
- 所有服务统统1实例，多卡1实例
- 我的分配方法

对比所有服务1卡多实例，能承载更高的qps且在这个qps下有更低的cpu内存消耗

对比所有服务多卡1实例，能承载更高的qps且在这个qps他的内存cpu消耗稍微高一些

**action details**

主要的工作是在

- 前期服务类型的判断

- 算法的编写

- 后期的性能测试

其实就是在集群资源有限的情况下，要尽可能让计算密集型的服务分配到多台机子上，而IO密集的尽量在更少的机器上

其实这个问题有点像背包问题，我们有多个机器，每台机器有GPU资源，就好像有多个背包，背包就是机器，容量就是GPU资源，对于不同的服务，不同的装法能够产生不同的价值，然后怎么装能够使得价值最大化。

但是我最后的解决方案其实并没有用背包的方法来解决，而是使用枚举的方式做的，主要有两点考虑

- 一是考虑到我们集群的资源是有限的，一个集群上的机器就十几台，使用动态规划的话主要是它有一些最优子结构，可以优化时间复杂度，但我们数据量是很小的，没有必要
- 二是为代码的可维护性、易读性考虑，写一个简单易懂的代码对自己或者后来者都是一种解脱吧

我想的方法就是对于一个服务，枚举它所有可能的划分方法，比如当前服务配了8卡，当前集群有4台机器，那么我们就可以4个实例两张卡，2个实例4张卡，1个实例八张卡，对于所有服务我们都这么做，然后我们将每一个服务都抽出一个划分方案出来，组合起来就得到一种所有服务的调度方案，我们可以将这些服务的划分方案一一组合，就能够得到所有的调度方案，对于每一个调度方案，怎么去区分它们是好是坏呢?

我们主要是基于一个点：让IO密集型服务尽可能在少的机器上运行，计算密集的服务尽可能平分到多台机器上，以充分利用CPU资源

所以我对每一个调度方案进行打分，

- 对于IO密集型的服务，它的分数是p/k，p是卡数，k是实例数，就说k越小它的分数就越大，
- 对于计算密集型的服务，它的分数是p*k/n，p是卡数，k是实例数，n是机器数，就是说k越大，它的分数越大。

给所有的调度方案打分之后，按照从大到小排序，分数越高其实就越符合我们的刚才基于的点

但其实并不是每一个调度方案都能够被大螺丝调度的，有些调度方案是不合理的，就比如说我们有2台4卡的机器，如果2个服务配4卡，一个服务的调度方案为1机器4卡，另一个服务2机器2卡，那么这样的调度方案是不合理的。

所以我需要使用一种方法去验证一种调度方案是否合理，我使用一种贪心的策略，去每次先放需求GPU卡多的到当前还剩GPU最多的机器上，如果有GPU卡分配不到任何一台机器上，那么就换下一个策略，如果能够分配完，就选择该种调度策略

针对配卡问题我也做了测试，一方面是功能测试，另一个是性能测试，功能测试主要测试配卡策略能不能够正常工作，能不能正确调度到集群，性能测试主要考虑两个点

- 一个是如何测试能够得到较为准确的负载，该负载应该与服务所能承载的真实负载接近
- 第二个是面对很多不同的服务，如何设计一套通用的测试框架以尽可能提高代码的可复用性、维护性、扩展性

实现，编写一个测试基类，有

- 线程安全的计数器
- 产生恒定QPS的压力控制器，内部使用一个线程安全的队列，往队列中按照恒定的QPS打数据，主任务从队列中取到数据才能发送请求，没有取到数据则等待
- 活性检查和qps统计
- 主任务，不同的服务有不同的逻辑

如果在某个qps内，在一段时间内，检测错误率不大于1%，且压力控制队列数据恒定，就说该服务能够承担这个QPS的压力

完成后的思考

缺点、如何在 k8s 层面解决问题

#### LruCache

situation

网站上经常展示一些摄像头抓拍的图片、用户人像库的图片，而这些图片存储在数据库中，每次获取图片需要从远端数据库中拿，这样延迟较高，限制了网站的qps

task

所以我的就一方面想对图片加缓存，另一方面这个缓存占用的内存还需要控制在一个相对固定的区间，

action

so引入了一种带有清退机制的缓存结构LruCache(Least Recently Used Cache)，在目前的系统中，使用LruCache + 键值存储数据库的机制将远端数据变为本地缓存数据，不仅能够降低平均获取信息的耗时，而且通过一定的清退机制，也可以维持服务内存占用在安全区间。

result

后端获取图片的延时降低了

**改进：Hash分片**

LruCache引入后，在一段时间内较好地支持了业务的发展。随着业务的迭代，单机QPS持续上升。在更高QPS下，LruCache的查询耗时有了明显的提高，逐渐无法适应低平响的业务场景。在这种情况下，引入了HashLruCache机制以解决这个问题。

LruCache在高QPS下的耗时增加原因分析：

线程安全的LruCache中有锁的存在。每次读写操作之前都有加锁操作，完成读写操作之后还有解锁操作。在低QPS下，锁竞争的耗时基本可以忽略；但是在高QPS下，大量的时间消耗在了等待锁的操作上，导致耗时增长。

HashLruCache适应高QPS场景：

针对大量的同步等待操作导致耗时增加的情况，解决方案就是尽量减小临界区。引入Hash机制，对全量数据做分片处理，在原有LruCache的基础上形成HashLruCache，以降低查询耗时。

HashLruCache引入某种哈希算法，将缓存数据分散到N个LruCache上。最简单的哈希算法即使用取模算法，将图片信息按照其ID取模，分散到N个LruCache上。查询时也按照相同的哈希算法，先获取数据可能存在的分片，然后再去对应的分片上查询数据。这样可以增加LruCache的读写操作的并行度，减小同步等待的耗时。

思考

改进的hash分片